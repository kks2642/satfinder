import requests, urllib.parse, pandas as pd, streamlit as st

# -----------------------------
# ì„¤ì •: ìœ„í‚¤/ìœ„í‚¤ë°ì´í„°/CELESTRAK
# -----------------------------
WIKI_API = {
    "en": "https://en.wikipedia.org/w/api.php",
    "ko": "https://ko.wikipedia.org/w/api.php",
}
WIKI_SUMMARY = {
    "en": "https://en.wikipedia.org/api/rest_v1/page/summary/",
    "ko": "https://ko.wikipedia.org/api/rest_v1/page/summary/",
}
WIKIDATA_ENTITY = "https://www.wikidata.org/wiki/Special:EntityData/"
CELESTRAK_TLE = "https://celestrak.org/NORAD/elements/gp.php"  # NAME=... & FORMAT=TLE

HEADERS = {"User-Agent": "SatFinder/1.1 (contact: student@example.com)"}


# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_data(ttl=3600, show_spinner=False)
def wiki_search_title(q: str, lang: str) -> str | None:
    """í•´ë‹¹ ì–¸ì–´ ìœ„í‚¤ë°±ê³¼ì—ì„œ ì œëª© ê²€ìƒ‰ â†’ ìµœìƒìœ„ ë¬¸ì„œ ì œëª© ë°˜í™˜"""
    r = requests.get(
        WIKI_API[lang],
        params={
            "action": "query",
            "list": "search",
            "srsearch": q,
            "format": "json",
            "srlimit": 1,
            "srprop": "",
        },
        headers=HEADERS,
        timeout=15,
    )
    hits = r.json().get("query", {}).get("search", [])
    return hits[0]["title"] if hits else None


@st.cache_data(ttl=3600, show_spinner=False)
def wiki_summary(title: str, lang: str) -> dict:
    """í•´ë‹¹ ì–¸ì–´ì˜ ìœ„í‚¤ REST ìš”ì•½"""
    r = requests.get(WIKI_SUMMARY[lang] + urllib.parse.quote(title), headers=HEADERS, timeout=15)
    return r.json() if r.status_code == 200 else {}


@st.cache_data(ttl=3600, show_spinner=False)
def wikidata_qid_from_title(title: str, lang: str) -> str | None:
    """í•´ë‹¹ ì–¸ì–´ ìœ„í‚¤ ì œëª© â†’ QID"""
    r = requests.get(
        WIKI_API[lang],
        params={"action": "query", "prop": "pageprops", "titles": title, "format": "json"},
        headers=HEADERS,
        timeout=15,
    )
    pages = r.json().get("query", {}).get("pages", {})
    for _, pg in pages.items():
        qid = pg.get("pageprops", {}).get("wikibase_item")
        if qid:
            return qid
    return None


@st.cache_data(ttl=3600, show_spinner=False)
def wikidata_entity(qid: str) -> dict:
    """ìœ„í‚¤ë°ì´í„° ì—”í‹°í‹°(ë¼ë²¨/í´ë ˆì„/ì‚¬ì´íŠ¸ë§í¬ í¬í•¨)"""
    r = requests.get(f"{WIKIDATA_ENTITY}{qid}.json", headers=HEADERS, timeout=20)
    ent = r.json().get("entities", {}).get(qid, {})
    return ent


def get_claim_value(ent: dict, prop: str, kind="time|str"):
    c = ent.get("claims", {})
    v = c.get(prop, [])
    if not v:
        return None
    mainsnak = v[0].get("mainsnak", {})
    dv = mainsnak.get("datavalue", {})
    val = dv.get("value")
    if not val:
        return None
    if kind == "time|str":
        return val.get("time") if isinstance(val, dict) else val
    return val


@st.cache_data(ttl=3600, show_spinner=False)
def celestrak_tle(name: str) -> list[str] | None:
    """Celestrak TLE ê²€ìƒ‰ (ì´ë¦„ ê·¸ëŒ€ë¡œ ì‹œë„)"""
    r = requests.get(
        CELESTRAK_TLE,
        params={"NAME": name, "FORMAT": "TLE"},
        headers=HEADERS,
        timeout=20,
    )
    if r.status_code != 200 or "No GP data" in r.text:
        return None
    lines = [l for l in r.text.strip().splitlines() if l.strip()]
    return lines[:3] if lines else None


def make_table(summary: dict, ent: dict | None, tle_lines: list[str] | None) -> pd.DataFrame:
    """í•µì‹¬ í•„ë“œ í‘œë¡œ ì •ë¦¬ (í•œêµ­ì–´ ìš°ì„ )"""
    # ê¸°ë³¸ ë©”íƒ€
    title = summary.get("title")
    desc = summary.get("description")
    extract = summary.get("extract")

    # ìœ„í‚¤ë°ì´í„° í´ë ˆì„
    launch_date = cospar_id = norad_id = None
    if ent:
        launch_date = get_claim_value(ent, "P619")  # ë°œì‚¬ì¼
        cospar_id = get_claim_value(ent, "P247")    # COSPAR
        norad_id = get_claim_value(ent, "P593")     # NORAD

    rows = [
        ("ì œëª©(Title)", title),
        ("ì„¤ëª…(Description)", desc),
        ("ë°œì‚¬ì¼(Launch Date)", launch_date),
        ("COSPAR ID", cospar_id),
        ("NORAD ID", norad_id),
    ]
    if tle_lines:
        rows += [
            ("TLE Name", tle_lines[0] if len(tle_lines) > 0 else None),
            ("TLE Line 1", tle_lines[1] if len(tle_lines) > 1 else None),
            ("TLE Line 2", tle_lines[2] if len(tle_lines) > 2 else None),
        ]
    return pd.DataFrame(rows, columns=["í•­ëª©(Field)", "ê°’(Value)"])


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="ğŸ›°ï¸ SatFinder | ìœ„ì„± ì¡°íšŒ", page_icon="ğŸ›°ï¸", layout="centered")
st.title("ğŸ›°ï¸ ì¸ê³µìœ„ì„± ì •ë³´ ê²€ìƒ‰ (Streamlit)")
st.caption("ìœ„í‚¤ë°±ê³¼/ìœ„í‚¤ë°ì´í„°/CELESTRAK ê³µê°œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (í•œêµ­ì–´ ìš°ì„  í‘œì‹œ)")

# ì˜ˆì‹œ ë²„íŠ¼ë“¤
st.caption("ì˜ˆì‹œ: í—ˆë¸” ìš°ì£¼ ë§ì›ê²½ / NOAA 19 / Sentinel-2A / ìŠ¤íƒ€ë§í¬-30000")
c1, c2, c3, c4 = st.columns(4)
if c1.button("í—ˆë¸” ìš°ì£¼ ë§ì›ê²½"):
    st.session_state["query"] = "í—ˆë¸” ìš°ì£¼ ë§ì›ê²½"
if c2.button("NOAA 19"):
    st.session_state["query"] = "NOAA 19"
if c3.button("Sentinel-2A"):
    st.session_state["query"] = "Sentinel-2A"
if c4.button("ìŠ¤íƒ€ë§í¬-30000"):
    st.session_state["query"] = "ìŠ¤íƒ€ë§í¬-30000"

default_q = st.session_state.get("query", "Hubble Space Telescope")
q = st.text_input("ìœ„ì„± ì´ë¦„ ë˜ëŠ” NORAD ID", default_q)
use_exact = st.checkbox("ì…ë ¥í•œ ì´ë¦„ìœ¼ë¡œ TLE ë¨¼ì € ê²€ìƒ‰", True)

if st.button("ê²€ìƒ‰"):
    if not q.strip():
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    # 1) ko â†’ en ìˆœì„œë¡œ ìœ„í‚¤ ì œëª© íƒìƒ‰
    with st.spinner("ìœ„í‚¤ ì œëª© ê²€ìƒ‰(koâ†’en) ì¤‘..."):
        title_ko = wiki_search_title(q, "ko")
        title_en = wiki_search_title(q, "en")

        # ì•„ë¬´ ê²ƒë„ ëª» ì°¾ìœ¼ë©´ ì¢…ë£Œ
        if not (title_ko or title_en):
            st.error("ìœ„í‚¤ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³µì‹ ëª…ì¹­ ë˜ëŠ” NORAD IDë¡œ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")
            st.stop()

    # 2) QID í™•ë³´ (koê°€ ìˆìœ¼ë©´ koë¡œ, ì—†ìœ¼ë©´ enìœ¼ë¡œ)
    with st.spinner("Wikidata(QID) í™•ì¸ ì¤‘..."):
        qid = None
        if title_ko:
            qid = wikidata_qid_from_title(title_ko, "ko")
        if not qid and title_en:
            qid = wikidata_qid_from_title(title_en, "en")

        ent = wikidata_entity(qid) if qid else None
        sitelinks = ent.get("sitelinks", {}) if ent else {}
        ko_title_from_qid = sitelinks.get("kowiki", {}).get("title") if sitelinks else None
        en_title_from_qid = sitelinks.get("enwiki", {}).get("title") if sitelinks else None

    # 3) í•œêµ­ì–´ ìš”ì•½ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´ ìš”ì•½
    with st.spinner("ìœ„í‚¤ ìš”ì•½(í•œêµ­ì–´ ìš°ì„ ) ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        summary = {}
        tried = []

        if ko_title_from_qid:
            summary = wiki_summary(ko_title_from_qid, "ko"); tried.append(("ko", ko_title_from_qid))
        if not summary and title_ko:
            summary = wiki_summary(title_ko, "ko"); tried.append(("ko", title_ko))
        if not summary and en_title_from_qid:
            summary = wiki_summary(en_title_from_qid, "en"); tried.append(("en", en_title_from_qid))
        if not summary and title_en:
            summary = wiki_summary(title_en, "en"); tried.append(("en", title_en))

        if not summary:
            st.error("ìš”ì•½ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

    # 4) TLE ê²€ìƒ‰: ì…ë ¥ê°’ â†’ ko/en ì œëª© ìˆœì„œë¡œ ì¬ì‹œë„
    with st.spinner("TLE ê²€ìƒ‰ ì¤‘..."):
        tle = celestrak_tle(q) if use_exact else None
        if tle is None:
            # ko/enì—ì„œ ì–»ì€ ì œëª©ë“¤ë¡œ ì¬ì‹œë„ (ì˜ë¬¸ì´ ë” ì˜ ë§ëŠ” í¸)
            for cand in [en_title_from_qid, title_en, ko_title_from_qid, title_ko]:
                if cand:
                    tle = celestrak_tle(cand)
                    if tle:
                        break

    # 5) ì¶œë ¥
    st.subheader("ğŸ“Œ ê°œìš” (í•œêµ­ì–´ ìš°ì„ )")
    st.write(f"**ì œëª©**: {summary.get('title')}")
    st.write(f"**ì„¤ëª…**: {summary.get('description') or 'â€”'}")
    if summary.get("extract"):
        with st.expander("ìš”ì•½ í¼ì¹˜ê¸°"):
            st.write(summary["extract"])

    st.subheader("ğŸ“Š ì„¸ë¶€ ì •ë³´")
    df = make_table(summary, ent, tle)
    st.dataframe(df, use_container_width=True)

    st.subheader("ğŸ§­ TLE")
    if tle:
        st.code("\n".join(tle))
    else:
        st.info("Celestrakì—ì„œ TLEì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. NORAD ID(ì˜ˆ: 20580)ë¡œ ì¬ì‹œë„í•´ ë³´ì„¸ìš”.")
